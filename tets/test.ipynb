{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-31T11:11:36.084086300Z",
     "start_time": "2024-08-31T11:11:32.446974100Z"
    }
   },
   "outputs": [],
   "source": [
    "import onnx\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from onnxruntime_extensions import pnp, OrtPyFunction\n",
    "from transformers import AutoTokenizer, GPT2LMHeadModel\n",
    "from transformers.onnx import export, FeaturesManager\n",
    "import onnxruntime as _ort\n",
    "from onnxruntime_extensions import get_library_path as _lib_path\n",
    "import numpy as np\n",
    "so = _ort.SessionOptions()\n",
    "so.enable_profiling = True\n",
    "so.register_custom_ops_library(_lib_path())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"textattack/bert-base-uncased-MRPC\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "mrpc_text1 = \"The quick brown fox jumps over the lazy dog\"\n",
    "mrpc_text2 = \"A fast brown fox leaps over a lazy dog\"\n",
    "dummy_input = tokenizer(mrpc_text1,\n",
    "                        mrpc_text2,  # MRPC 是句子对任务\n",
    "                        max_length=128,  # 设置合适的最大长度\n",
    "                        truncation=True,  # 启用截断\n",
    "                        padding='max_length',  # 启用填充到最大长度\n",
    "\n",
    "                        );\n",
    "# dict(dummy_input)\n",
    "# for key in dummy_input.keys():\n",
    "#     dummy_input[key] = dummy_input[key].tolist()\n",
    "dummy_input = dict(dummy_input)\n",
    "dummy_input.keys()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-31T11:11:46.221361200Z",
     "start_time": "2024-08-31T11:11:36.083086300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Inputs:\n",
      "input\n",
      "Model Outputs:\n",
      "output\n",
      "172\n"
     ]
    }
   ],
   "source": [
    "# 加载onnx模型，查看输入输出名字\n",
    "model_path = r\"D:\\project\\inference_controller\\tets\\model_0.onnx\"\n",
    "model = onnx.load(model_path)\n",
    "# 获取模型图\n",
    "graph = model.graph\n",
    "# 打印输入名称\n",
    "print(\"Model Inputs:\")\n",
    "for input in graph.input:\n",
    "    print(input.name)\n",
    "\n",
    "# 打印输出名称\n",
    "print(\"Model Outputs:\")\n",
    "for output in graph.output:\n",
    "    print(output.name)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-31T11:11:46.288732900Z",
     "start_time": "2024-08-31T11:11:46.221361200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "dummy_input = np.zeros((1, 3,32,32), dtype=np.float32)\n",
    "session = _ort.InferenceSession(model_path, so)\n",
    "re = session.run(None, {\"input\": dummy_input})\n",
    "profile_file = session.end_profiling()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-31T11:13:38.470131300Z",
     "start_time": "2024-08-31T11:13:38.447108700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "'onnxruntime_profile__2024-08-31_19-13-38.json'"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profile_file"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-31T11:13:42.297405200Z",
     "start_time": "2024-08-31T11:13:42.284161300Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
